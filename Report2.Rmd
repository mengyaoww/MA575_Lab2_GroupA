---
title: "Report 2"
author: "Lab2 GroupA"
date: "2025-02-07"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,    # Show the R code in the final output.
  fig.pos = "!h"  # Suggests to position figures "here" in the output.
)
```

```{r message=FALSE}
### load the library
library(dplyr)
library(ggplot2)
library(cowplot) #to arrange ggplot
library(GGally)
library(MASS) #for boxcox
### load the data
dat_bmw <- read.csv("BMWpricing_updated.csv")
```

### address missing data

```{r}
### Assigning NA to data points with negative mileage
dat_bmw[dat_bmw$mileage < 0, "mileage"] <- NA
### Converting mileage, engine power, and price into numeric
dat_bmw[,c(3,4,17)] <- apply(dat_bmw[,c(3,4,17)], 2, as.numeric)
### Create a data frame only has the variable of interests
dat_bmw2 <- dat_bmw[,c("price", "mileage", "engine_power")]
### Drop the data point with NA
dat_bmw2 <- dat_bmw2[complete.cases(dat_bmw2),]
# summary(dat_bmw)
```

### scatterplot matrix

```{r, fig.width=6, fig.height=4, fig.show = "hold"}
ggpairs(dat_bmw2,
        upper = list(continuous = wrap("points", alpha = 0.3, size = 0.1)),
        lower = list(continuous = wrap("cor", size = 4))) +
  labs(title = "Distribution and Correlation between Price, Mileage, and Engine Power") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8),
        axis.text.y = element_text(size = 8),
        title = element_text(size = 8))
```

#### scatter plot of price and mileage

We first set the negative mileage (in one sample) as the missing data and excluded it in our following analysis.\
Our scatter plot shows a negative correlation between price and mileage,  indicating that price tends to decrease as mileage increases. However, this relationship is not strongly linear and a straight-line regression model may not be the best option. We find some problems in our data: 1) Both price and mileage follow highly right-skewed distributions; 2) There are some high leverage points on the right side of the scatter plot, especially the red point with around 1000000 miles; 3) Outliers with extreme high sold prices are observed on the top-left of the plot, especially these blue points with price over 100000.\
We further transform price based on the log-likelihood for the Box-Cox transformation method. Though the $\lambda$ with the greatest log-likelihood ($\lambda_{price} = 0.4, \lambda_{mileage} = 0.7$) and its 95% CI do not include 0, 0.5, and 1, there are slight differences in log-likelihood for price when $\lambda \in [0,0.5]$ and for mileage when $\lambda \in [0.5,1]$. For interpretability, we finally apply log-transformation on the price and keep the mileage in the data.\
In the scatter plot of log(price) and mileage, we observe some potential outliers with low prices and short mileage.

```{r}
# Scatter plot of price vs. mileage with highlighted outliers
scatterPlotPriceMileage <- ggplot(data = dat_bmw2, mapping = aes(x = mileage, y = price)) +
  geom_point(pch=19, cex=0.3) +  # Default points
  geom_point(data = subset(dat_bmw2, mileage > 500000), mapping = aes(x = mileage, y = price), pch=19, cex=1, color = "red") +  # Highlight points with mileage > 500000 in red
  geom_point(data = subset(dat_bmw2, price > 100000), mapping = aes(x = mileage, y = price), pch=19, cex=1, color = "blue") + # Highlight points with price > 100000 in blue
  labs(title = "Scatter plot between price and mileage") +
  theme_bw() + theme(title = element_text(size=8)) 

# Box-Cox transformation for the price variable
boxcox_price <- boxcox(lm(dat_bmw2$price ~ 1), plotit = F)
boxcox_priceDF <- data.frame("lambda" = boxcox_price$x, "ll" = boxcox_price$y)
maxlabmda_price <- boxcox_price$x[which.max(boxcox_price$y)]

# Box-cox Plot for the price variable
boxcoxPlotPrice <- ggplot(data = boxcox_priceDF, mapping = aes(x = lambda, y = ll)) +
  geom_line(color = "black", linewidth = 0.5) +
  geom_vline(xintercept = maxlabmda_price, linetype = "dashed", color = "red") +
  geom_hline(yintercept = max(boxcox_price$y) - qchisq(0.95, df = 1)/2, linetype = "dashed", color = "blue") +
  labs(title = "Log-likelihood for the Box-Cox transformation",
       x = expression(lambda),
       y = "Log-likelihood for price") +
  annotate("text", label = paste0("lambda ==", maxlabmda_price), x = 1, y = -30000, parse = T) +
  theme_bw() + theme(title = element_text(size=8)) 

# Box-cox transformation for the mile variable
boxcox_mile <- boxcox(lm(dat_bmw2$mileage ~ 1), plotit = F)
boxcox_mileDF <- data.frame("lambda" = boxcox_mile$x, "ll" = boxcox_mile$y)
maxlabmda_mile <- boxcox_mile$x[which.max(boxcox_mile$y)]

# Box-cox Plot for the mile variable
boxcoxPlotMile <- ggplot(data = boxcox_mileDF, mapping = aes(x = lambda, y = ll)) +
  geom_line(color = "black", linewidth = 0.5) +
  geom_vline(xintercept = maxlabmda_mile, linetype = "dashed", color = "red") +
  geom_hline(yintercept = max(boxcox_mile$y) - qchisq(0.95, df = 1)/2, linetype = "dashed", color = "blue") +
  labs(title = "Log-likelihood for the Box-Cox transformation",
       x = expression(lambda),
       y = "Log-likelihood for mileage") +
  annotate("text", label = paste0("lambda ==", maxlabmda_mile), x = 1, y = -30000, parse = T) +
  theme_bw() + theme(title = element_text(size=8)) 

# Create a column of logprice in dat_bmw2
dat_bmw2 <- dat_bmw2 %>% mutate(logprice = log(price))

# Scatter plot of logprice vs. mileage with highlighted outliers
scatterPlotLogPriceMileage <- ggplot(data = dat_bmw2, mapping = aes(x = mileage, y = logprice)) +
  geom_point(pch=19, cex=0.3) +
  geom_point(data = subset(dat_bmw2, mileage > 500000), mapping = aes(x = mileage, y = logprice), pch=19, cex=1, color = "red") +
  geom_point(data = subset(dat_bmw2, logprice > log(100000)), mapping = aes(x = mileage, y = logprice), pch=19, cex=1, color = "blue") +
  labs(title = "Scatter plot between log(price) and mileage") +
  theme_bw() + theme(title = element_text(size=8)) 

plot_grid(scatterPlotPriceMileage, boxcoxPlotPrice, boxcoxPlotMile, scatterPlotLogPriceMileage, align = "h")
```

### Outliers

```{r}
modelDF <- dat_bmw2
### Assigning NA to car with mileage > 50,0000 miles
modelDF[modelDF$mileage > 500000, "mileage"] <- NA 
### Assigning NA to car with price > 100000 usd
modelDF[modelDF$price > 100000, "price"] <- NA
modelDF <- modelDF[complete.cases(modelDF),]
modelDF$logprice <- log(modelDF$price)
```

#### model fitting

We have used an Ordinary Least Square regression model to predict the natural logrithm of BMW car prices from mileage. The model may be represented as:

$$
log(price) = \beta_0+\beta_1\times mileage + \epsilon 
$$

The residuals tell us about the difference between the model-predicted values and the actual logprice values. These should ideally be symmetrically distributed around zero, and that would be a good-behaved model. But the minimum of residual is –5.1907. However, the minimum of residual is –5.1907. That means that, for at least one observation, the model-predicted log(price) is much larger than the actual value.

The "Coefficients" section provides us with detailed statistics for the intercept and the mileage coefficient. The intercept is estimated to be 10.17 with very small standard error (0.02175) and thus having an extremely large t-value of 467.7 and an extremely small p-value of less than 2e-16. This is very strong evidence against the null hypothesis that the intercept is zero. Similarly, mileage coefficient is also estimated as –4.746e-06, which means that for one unit increase in mileage, logprice decreases by about 4.746e-06 units. Its standard error is 1.425e-07, which yields a t-value of –33.3 and a p-value similarly less than 2e-16. These allow us to reject the null hypothesis for both coefficients, meaning mileage is a statistically significant logprice predictor.

Besides the individual coefficients, the fit of the entire model is also tested by means of the F-test. The F-statistic of 1109 with degrees of freedom 1 and 4837, and p-value smaller than $2.2 \times 10^{-16}$ tests whether the model that includes mileage as a predictor explains significantly more variation in log(price) than does a model with no predictors. This result confirms that our model as a whole is statistically significant although mileage by itself explains only about 18.65% of the variation in log(price) (as indicated by the Multiple R-squared of 0.1865). The quite low R-squared does suggest, however, that while mileage is an important predictor, there are other variables that probably have roles to play in explaining variations in car price.

```{r}
mod1 <- lm(logprice ~ mileage, data = modelDF)
summary(mod1)
```

```{r}
# Create a scatter plot with the best-fit line
# Add predicted values to the dataset
modelDF$predLinear <- predict(mod1)

# Create the scatter plot with the best-fit line
ggplot(modelDF, aes(x = mileage, y = logprice)) +
  geom_point(size = 0.15, color = 'blue') +                       # Scatter plot points
  geom_line(aes(x = mileage, y = predLinear, color = "blue")) +     # Best-fit line from predictions
  scale_color_discrete(name = "Prediction", labels = c("Linear")) + # Legend for the line
  theme_bw()
```
